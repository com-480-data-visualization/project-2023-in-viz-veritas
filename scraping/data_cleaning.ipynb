{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(text):\n",
    "    if not len(text):\n",
    "        return text\n",
    "    \n",
    "    len_before = len(text)\n",
    "    len_after = -1\n",
    "\n",
    "    # idk why, but some phrases need multiple passes until convergence\n",
    "    # i am sure this could be done in a single pass, but this is good enough\n",
    "    while len_before != len_after:\n",
    "        len_before = len(text)\n",
    "        words = text.split()\n",
    "        offset = 0\n",
    "        for elem in words:\n",
    "            first_appearance = text.find(elem, offset, len(text))\n",
    "\n",
    "            offset = first_appearance + 1\n",
    "            second_appearance = text.find(elem, first_appearance + len(elem), len(text))\n",
    "\n",
    "            phrase_length = second_appearance - first_appearance\n",
    "\n",
    "            if second_appearance != -1:\n",
    "                first_phrase = text[first_appearance:second_appearance].strip()\n",
    "                second_phrase = text[second_appearance:second_appearance+phrase_length].strip()\n",
    "\n",
    "\n",
    "                if first_phrase == second_phrase:\n",
    "                    text = ''.join(text[:first_appearance] + text[second_appearance:])\n",
    "                    offset = second_appearance\n",
    "        len_after = len(text)\n",
    "    \n",
    "    return text.format('utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [01:39<00:00,  1.28s/it]\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(os.listdir('./data/transcripts/raw')):\n",
    "    if file.endswith('.json'):\n",
    "        test_file = json.load(open('./data/transcripts/raw/' + file))\n",
    "\n",
    "        for i in range(len(test_file['pages'])):\n",
    "            for j, text in enumerate(test_file['pages'][i]):\n",
    "                test_file['pages'][i][j] = remove_duplicates(text)\n",
    "\n",
    "        json.dump(test_file, open('./data/transcripts/no_doubles/' + file, 'w'), indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
